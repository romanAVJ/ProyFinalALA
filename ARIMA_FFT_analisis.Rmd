---
title: "ARIMA and FFT fit"
output: html_notebook
---

```{r libraries}
library(ggplot2)
library(forecast)
library(dplyr)
library(lubridate)
library(purrr)
library(data.table)
library(TSA)
```


Primero se analizará la serie de tiempo vía modelos ARIMA y luego una FFT.

# EDA

Se ajustarán los datos de los últimos 70 días, debido a que son los que tienen más pronunciada su estacionalidad. La fecha de corte fue
el 25 de mayo del 2020.
```{r edatrans}
# read data
df_trans <- read.csv(file = 'Data/trans_all.csv', header = TRUE, stringsAsFactors = FALSE) %>% map_df(rev)
n <- nrow(df_trans)
trans60 <- df_trans[(n-69):n, 'num_trans'] %>% as.matrix()

# parse data to ts object (forecast)
# create daily times from
inds <- seq(as.Date('2020-03-06'), as.Date('2020-05-24'), by = 'day')
ts_trans <- ts(trans60, start = c(2020, as.numeric(format(inds[1], '%j'))), frequency = 7)

```

Graficamos la serie de tiempo y su posible estacionalidad

```{r edatransplot}
# plot time series
plot.ts(ts_trans)
autoplot(ts_trans, color = 'navy') + xlab('Tiempo') + ylab('Transacciones') +  theme_minimal() + theme(axis.text.x = element_blank(), legend.position = "none") + ggtitle('Serie de tiempo')
# plot seasonality
# linear
ggseasonplot(ts_trans, season.labels = TRUE, show.legend = FALSE) +xlab('Día de la semana') + ylab('Transacciones') +  theme_minimal() + ggtitle('Serie de tiempo estacional sin nivel') + theme(legend.position = "none")

#polar
ggseasonplot(ts_trans, season.labels = TRUE, polar = TRUE) +xlab('Día de la semana') + ylab('Transacciones') +  theme_minimal() + ggtitle('Serie de tiempo estacional sin nivel') +  theme(legend.position = "none")

# mean value by day
ggsubseriesplot(ts_trans) + xlab('Tiempo') + ylab('Transacciones') +  theme_minimal() +  ggtitle('Serie de tiempo estacionalizada sin nivel')

#lag plots
gglagplot(ts_trans) # look all the noise except for lag 7 

# data-seasonal-trend-reminder
descomposedTS <- stl(ts_trans[,'num_trans'], s.window = 'periodic') 
descomposedTS %>% autoplot()


```

## Estacionar la serie e inducir normalidad


### Tranformación Box-Cox
Usamos el método de Victor Guerrero para encontrar la transofrmación estabilizadora de varianza
```{r}
# lambda
lambda <- ts_trans %>%  BoxCox.lambda(method = 'guerrero') # lambda = 1 ==> no more changes
#ts_trans <- BoxCox(ts_trans, lambda = lambda)
```

### Diferenciación

```{r}
# look trend
ggtsdisplay(ts_trans)


# differentiate
ts_transD <- diff(ts_trans)

# plot new trend
ggtsdisplay(ts_transD)


# function to determine number of appropiate differences
(ndif <- ndiffs(ts_trans)) #0 
#(p <- periodogram(ts_trans))
# level
mu <- mean(ts_trans)

# new serie
#ts_trans <- ts_trans - mu
```





# FFT Analisis

## Frequency domain observations.

_NOTA:_ 

- NO SE PORQUÉ, pero el primer término lo debemos quitar. Creo que es porque en la matriz de la FFT, el primer renglon son 1's y entonces sería como el "promedio espectral" y pues no tiene mucho sentido.
- Como $n$ es par, solo necesitamos la mitad de la info para tomar la frecuencia
- Se me hace muy raro los datos del 30 a 40 queda en 0.

Observamos estacionalidad "decreciente" (valores mayores a 7.5)

Como no empieza en domingo la serie, está desfazado por __dos__ días la estacionalidad. Vemos que si hay, aunque tenue, periodicidad cada 7 días en jueves. Como el EDA de series de tiempo proponía.

```{r }
# fast fourier transform
n <- 70 # total data
df_fft <- data.frame(coef = fft(trans60) / 70, freqindex = 1:70)

# look to the spectrum
df_fft[2:n,] %>% 
  ggplot(aes(freqindex, Mod(num_trans))) + 
  geom_line(color = 'black') + 
  geom_point(color = 'red') + 
  xlab('Índice de frecuencia') +
  ylab('Módulo complejo') +
  theme_minimal()

# identify peaks
df_fft[ Mod(df_fft$num_trans) > 7.5 & df_fft$freqindex < n/2, 'freqindex' ] - 1

```

## Fourier y series de tiempo

```{r nffFunction}

nff <-  function(x = NULL, n = NULL, up = 10L, plot = TRUE, add = FALSE, main = NULL, ...){
  #size of the signal
  N <- length(x)
  
  #The direct transformation
  #The first frequency is DC, the rest are duplicated
  dff <-  fft(x)
  #The time
  t <-  seq(from = 1, to = N)
  #Upsampled time
  nt <-  seq(from = 1, to = N+1-1/up, by = 1/up)
  
  #New spectrum
  ndff <-  array(data = 0, dim = c(length(nt), 1L))
  ndff[1] <-  dff[1] #Always, it's the DC component
  if(n != 0){
    ndff[2:(n+1)] <-  dff[2:(n+1)] #The positive frequencies always come first
    #The negative ones are trickier
    ndff[length(ndff):(length(ndff) - n + 1)] <-  dff[N:(N - n + 1)]
  }
  
  #The inverses
  indff <-  fft(ndff/N, inverse = TRUE) ### !
  idff <-  fft(dff/N, inverse = TRUE) ### ! N - 73
  if(plot){
    if(!add){
      plot(x = t, y = x, pch = 16L, xlab = "Tiempo", ylab = "Transacciones",
        main = ifelse(is.null(main), paste(n, "armónicas"), main))
      lines(y = Mod(idff), x = t, col = adjustcolor(1L, alpha = 0.5))
    }
    lines(y = Mod(indff), x = nt, ...)
  }
  ret <-  data.frame(time = nt, y = Mod(indff))
  return(ret)
}


```

```{r}
# look different number of armonics
nff(x = trans60, n = 7L, up = 70L, col = 2L)
nff(x = trans60, n = 14L, up = 200L, col = 'navy')
nff(x = trans60, n = 20L, up = 200L, col = '#FDE725FF')

```
Grafiquemos todas las armónicas

(hay que citar a este gran wei https://stackoverflow.com/questions/41435777/perform-fourier-analysis-to-a-time-series-in-r/41465250)
```{r}
colors <- viridis::viridis(15)
for(i in 1:15){
  ad = ifelse(i == 1, FALSE, TRUE)
  nff(x = trans60, n = i, up = 100L, col = colors[i], add = ad, main = "Todos los wavelets hasta la armónica 15")
}



```


# ARIMA 

Ahora construimos el modelo ARIMA. Sabemos de antemano que $\lambda = 1$ y que $\nabla = 0$, por lo que se trabajará con la serie original.

Al ver la AC y ACP de la serie de tiempo, es razonable pensar en un modelo ARMA({1,2},{4})Est({7})Season, pero veamos el modelo que el algoritmo escoje.

Vemos que el modelo que escoje es un modelo MA1, este modelo lo modemos pasar como AR($\infty$), (desarrollar serie geométrica). Esto puede explicar la transaccionalidad como una función de ellas mismas con respecto al _periodo_ pasado, no al día anterior. 

Se realizó una búsqueda más potente, pero la log verosimilitud mejoró prácticamente nada y por el principio de _parsimonia_ nos quedamos con el modelo ARIMA(0,0,0)(0,1,1)[7]. Hay que comprobar supuestos para poder usar dicho modelo.

```{r}
# recomended model from forecast package
#fit1 <- auto.arima(ts_trans, approximation = FALSE,  stepwise = FALSE) # harder search
fit2 <- auto.arima(ts_trans) # simpler search
#fit1
fit2
```

Por lo anterior, hacemos el ajuste del modelo ARIMA(0,0,0)(0,1,1)[7]

```{r}
# look ACF and PACF 
ts_trans %>% diff(lag = 7) %>% ggtsdisplay()
#ggtsdisplay(fit2)
```
Vemos que efectivamente es un modelo ARIMA(0,0,0)(0,1,1)[7], aunque pudiera pensarse también en un ARIMA(3,0,0)(1,1,0)[7] cuyos coeficientes 1 y 2 son ceros. Por tanto trabajaremos con _fit2_ (si da tiempo metemos este ultimo modelo).

## Check assumptions

Por las graficas a continuación, la prueba Q-Ljung-Box y los valores atípicos, tenemos un modelo "válido".

```{r}
# 1. ACF & PACF for residuals
fit2 %>% residuals() %>% ggtsdisplay() #looks good

# 2. Check normality
fit2 %>% checkresiduals() #p-value 0.2, ok

# 3. Look outliers
fit2 %>% residuals() %>% boxplot() # 3 outliers
fit2 %>% residuals() %>% qqnorm() # 3 outliers
fit2 %>% residuals() %>% qqline() 
```

## Ajuste visual
```{r}
# plot
# serie original con una diferencia
serie <- diff(ts_trans, differences = 1, lag = 7)

plot(fit2$x)
#lines(ts_trans, col = "red")
lines(fitted(fit2),col="blue", lty = 2, lwd = 0.5)
```



## Predicción 

Predecimos para las dos semanas con doble IC al nivel 80% y 95%.

```{r}
# forecast
fit2 %>% forecast(h = 14, level = c(80,95)) %>% autoplot()


```

# Modelo de regresión dinámico armónico

A continuación ajustaremos un modelo armónico con error ARIMA. Los coeficientes de fourier sólamente pueden llegar hasta $m/2$, donde m siginifca el periodo.

Vemos que el que mejor captura la información es el que tiene 3 coeficientes de fourier
```{r}
# intialize
plots <- list()

# take out seasonality
#ts_transDS <- ts_trans %>% diff(lag = 7)

# routine to gather the best number of harmonics
for (i in 1:3){
  # fit model
  fit <- auto.arima(ts_trans, xreg = fourier(ts_trans, K = i), # K = i number of harmonics
                    seasonal = FALSE, lambda = 1, stepwise = FALSE, approximation = FALSE)
  
  # save plots
  plots[[i]] <- fit %>% 
                forecast(xreg = fourier(ts_trans, K = i, h = 14)) %>% 
                autoplot() +
                xlab(paste('K=',i,'  AICc =', round(fit[['aicc']],2))) +
                ylab('') 
  
}

# plot
gridExtra::grid.arrange(
  plots[[1]],
  plots[[2]],
  plots[[3]],
  nrow = 3
)

fit4 <- auto.arima(ts_trans, xreg = fourier(ts_trans, frequK = 3), 
                   seasonal = TRUE, lambda = 1, stepwise = FALSE, 
                   approximation = FALSE)  # K = i number of harmonics
fit4
#fit4 <- arima(ts_trans,seasonal = list(order=c(0,1,0), period = 7), xreg = fourier(ts_trans, K = 3))

autoplot(forecast(fit4, xreg = fourier(ts_trans, K = 3,h = 14)))

```

## Ajuste visual
```{r}
# plot
plot(fit4$x) # no me sale
#lines(serie, col = "blue")
lines(fit4$fitted,col="blue", lty = 3, lwd = 0.5)

# residuals
plot(fit4$residuals, col = "red")
lines(fit2$x, col = "green")
lines(serie, col = "blue")
lines(ts_trans, col = "yellow")
```



# TBATS: Modelo trigonométrico, BoxCox, Autoregresivo, estacional.

Vemos que se consiguio un modelo ARMA(0,0), sin damping y _dos_ coeficientes de fourier con estacionalidad 7. (Lo que habíamos ya conseguido). Vemos que es MUY parecdio al modelo ARIMA, aunque con una tendencia de crecimiento aún más pequeña.
```{r}
# tbats model
(fit3 <- ts_trans %>% tbats(use.box.cox = FALSE))
#fit3 <- tbats(ts_trans)
# look model
fit3

# predict
fit3 %>% forecast(h = 14, level = c(80,95)) %>% autoplot()

```

## Ajuste visual
```{r}
plot(fit3$y)
lines(fitted(fit3),col="blue", lty = 2, lwd = 0.5)
```

Comparación entre modelos
```{r}
plot(ts_trans, main ="Serie Real vs Modelos", ylab = "Transacciones", xlab = "Tiempo")
lines(fit2$fitted, col = "blue", lty = 2)
lines(fit4$fitted, col = "green", lty = 2)
lines(fit3$fitted.values, col = "red", lty = 2)
legend("topright",legend=c("ARIMA", "Reg Fourier", "TBATS"), lty=c(0,0), pch=c(16, 16), col=c("blue", "green", "red"))
```

Múltiples predicciones
```{r}
txnNuevas <- read.csv(file = 'Data/lastTrans.csv', header = TRUE, stringsAsFactors = FALSE)
txns <- ts(txnNuevas$num_trans, start = c(2039,3), frequency = 7)


pronos1 <- forecast(fit2, h = 7,level = 80)
pronos2 <- forecast(fit4, xreg = fourier(ts_trans, K = 3,h = 7),level = 80)
pronos3 <- forecast(fit3, h = 7,level = 80)
ts.plot(txns,pronos1$mean,pronos2$mean, pronos3$mean, gpars = list(col = c("black", "blue", "green", "red"),main ="Valores reales vs pronosticos"))
legend("topright",legend=c("ARIMA", "Reg Fourier", "TBATS"), lty=c(0,0), pch=c(16, 16), col=c("blue", "green", "red"))
```

Calidad de los pronósticos
```{r}
accuracy(pronos1,txns)
accuracy(pronos2,txns)
accuracy(pronos3,txns)
```


















